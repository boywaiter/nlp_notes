{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_notes02.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/boywaiter/nlp_notes/blob/master/nlp_notes02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0n8PJvbajLHm",
        "colab_type": "text"
      },
      "source": [
        "# Chapter 2 Linear Text Claasification\n",
        "\n",
        "**text classification**: given a text document, assign it a discrete label $y\\in\\mathcal{Y}$, where $\\mathcal Y$ is the set of possible labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-pkPKHVkP6",
        "colab_type": "text"
      },
      "source": [
        "## 2.1 The bag of words\n",
        "A document or an instance is represented as a column vector, $\\boldsymbol x=[0, 1, 1, 0, 0, 2, 0, 1, 13, 0 ,\\ldots]^\\textrm{T}$, where $x_j$ is the count of the $j$-th word. The length of $\\boldsymbol x$ is $V=|\\mathcal V|$, the size of vocabulary.\n",
        "\n",
        "**Bag of words**: contains only word count information, no order information of words.\n",
        "\n",
        "**Weights** $\\boldsymbol \\theta$ assigns for each word a score, measuring the compatability with the label.\n",
        "\n",
        "To predict the label $\\hat y$ for a given $\\boldsymbol x$, we compute a score $\\Psi(\\boldsymbol x, y)$ for each $y\\in \\mathcal Y$,\n",
        "$$\n",
        "\\Psi (\\boldsymbol x, y)= \\mathbf \\theta \\cdot \\boldsymbol f(\\boldsymbol x, y)=\\sum_{j=1}^V \\theta_j\\cdot f_j(\\boldsymbol x,y) \\tag{2.1}\n",
        "$$\n",
        "where, it may seem awkward, the $\\boldsymbol f(\\boldsymbol x, y)$ returns a column vector of length $K\\times V$ and with $(K-1)\\times V$ zeros,  \n",
        "$$\n",
        "{\\boldsymbol{f}(\\boldsymbol{x}, y=1)=[\\boldsymbol{x} ; \\underbrace{0 ; 0 ; \\ldots ; 0}_{(K-1)\\times V}] }\\\\ \\tag{2.3}\n",
        "$$\n",
        "$$\n",
        "{\\boldsymbol{f}(\\boldsymbol{x}, y=2)=[\\underbrace{0 ; 0 ; \\ldots ; 0 }_{V};\\boldsymbol{x} ; \\underbrace{0 ; 0 ; \\ldots ; 0}_{(K-2)\\times V}]}\\tag{2.4}\n",
        "$$\n",
        "$$\n",
        "{\\boldsymbol{f}(\\boldsymbol{x}, y=K)=[\\underbrace{0 ; 0 ; \\ldots ; 0}_{(K-1) \\times V} ; \\boldsymbol{x}]}\\tag{2.5}\n",
        "$$\n",
        "The weights $\\boldsymbol \\theta$ is thus a column vector of the length $K\\times V$, i.e., $\\boldsymbol \\theta\\in \\mathbb R^{KV}$, where $\\theta_{(k-1)*V+1:kV}$ are for label $y=k$. \n",
        "\n",
        "We predict the label $\\hat y$ with\n",
        "$$\n",
        "\\hat y =\\mathop{\\text{argmax}}\\limits_{y\\in \\mathcal Y} \\Psi(\\boldsymbol x,y)\\tag{2.6}\n",
        "$$\n",
        "$$\n",
        "\\Psi(\\boldsymbol x,y )=\\boldsymbol \\theta\\cdot\\boldsymbol f(\\boldsymbol x,y)\\tag{2.7}\n",
        "$$\n",
        "It is common to add an **offset feature** at the end of $\\boldsymbol x$, which is always 1. The weight for it can be thought of as a bias.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybolQlb2nrFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMMhPHcBr6Ls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K=3\n",
        "V=5\n",
        "x=torch.randint(10,(V,1))\n",
        "x=torch.cat((x,torch.ones(1,1,dtype=torch.long)),0)#offset features\n",
        "weights=torch.ones(K*(V+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xzuf5jq7salE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_function(x,y):\n",
        "  return {(y-1)*(V+1)+i:x[i] for i in range(0,V+1)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDsL37OipVbM",
        "colab_type": "code",
        "outputId": "fd0c8934-35f2-43a2-e3b2-48e7a02cbc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(feature_function(x,2))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{6: tensor([7]), 7: tensor([5]), 8: tensor([8]), 9: tensor([7]), 10: tensor([1]), 11: tensor([1])}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg8wcWx6jAn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_score(x,y,weights):\n",
        "  total=0\n",
        "  for feature, count in feature_function(x,y).items():\n",
        "    total+=weights[feature] * count\n",
        "  return total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr1W6rTjpRaT",
        "colab_type": "code",
        "outputId": "eabd96f8-2063-4a85-a787-1184a5596060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(x)\n",
        "print(weights)\n",
        "total=compute_score(x,2,weights)\n",
        "print(total)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[7],\n",
            "        [5],\n",
            "        [8],\n",
            "        [7],\n",
            "        [1],\n",
            "        [1]])\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n",
            "tensor([29.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0v-f5cKV0EO",
        "colab_type": "text"
      },
      "source": [
        "## 2.2 Naive Bayes\n",
        "$\\textrm{p}(\\boldsymbol x, y)$ is the **joint probability** of a text instance. A dataset of $N$ labeled instances is $\\{(\\boldsymbol x^{(i)}, y^{(i)})\\}_{i=1}^N$. We assume these instances are **independent and identically distributed (IID)**, i.e., $\\textrm{p}(\\boldsymbol x, y)=\\prod_{i=1}^N \\textrm{p}(\\boldsymbol x^{(i)}, y^{(i)})$.\n",
        "\n",
        "**Maximum Likelihood Estimation**:\n",
        "$$\n",
        "\\begin{eqnarray}\n",
        "\\hat y &=& \\mathop{\\text{argmax}}\\limits_\\boldsymbol \\theta \\textrm{p}(\\boldsymbol x, y;\\boldsymbol \\theta)\\tag{2.8}\\\\\n",
        "&=&\\mathop{\\text{argmax}}\\limits_\\boldsymbol \\theta\\prod_{i=1}^N \\textrm{p}(\\boldsymbol x^{(i)}, y^{(i)};\\boldsymbol \\theta) \\tag{2.9}\\\\\n",
        "&=&\\mathop{\\text{argmax}}\\limits_\\boldsymbol \\theta\\sum_{i=1}^N \\log\\textrm{p}(\\boldsymbol x^{(i)}, y^{(i)};\\boldsymbol \\theta)\\tag{2.10}\n",
        "\\end{eqnarray}\n",
        "$$\n",
        "The probability $\\textrm{p}(\\boldsymbol x^{(i)}, y^{(i)};\\boldsymbol \\theta)$ is defined through a generative model â€” an idealized\n",
        "random process that has generated the observed data. The joint probability is factored using the chain rule,\n",
        "$$\n",
        "\\textrm{p}(\\boldsymbol x^{(i)}, y^{(i)};\\boldsymbol \\theta)=\\textrm{p}(\\boldsymbol x^{(i)}| y^{(i)};\\boldsymbol \\phi)\\times \\textrm{p}(y^{(i)};\\boldsymbol \\mu)\\tag{2.11}\n",
        "$$\n",
        "where $\\boldsymbol \\theta=\\{\\boldsymbol \\mu, \\boldsymbol \\phi\\}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9etGacWYI2oR",
        "colab_type": "text"
      },
      "source": [
        "2.3 Discriminative learning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocxpovpcuJuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Word_count_max=10\n",
        "N=10\n",
        "V=5\n",
        "K=2\n",
        "X=torch.randint(low=1,high=Word_count_max,size=(N,V))\n",
        "X=torch.cat((X,torch.ones(N,1,dtype=torch.long)),1)\n",
        "y=torch.randint(0,K,size=(N,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3ozlmioGkzx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "e2f32e4f-68f6-4147-8f79-1a232d321e1f"
      },
      "source": [
        "print(X)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[2, 1, 3, 2, 9, 1],\n",
            "        [5, 7, 3, 9, 7, 1],\n",
            "        [2, 9, 3, 7, 4, 1],\n",
            "        [6, 5, 3, 8, 1, 1],\n",
            "        [2, 1, 9, 9, 3, 1],\n",
            "        [8, 1, 5, 3, 1, 1],\n",
            "        [5, 9, 2, 3, 5, 1],\n",
            "        [3, 8, 8, 2, 2, 1],\n",
            "        [1, 8, 3, 1, 7, 1],\n",
            "        [7, 7, 8, 5, 8, 1]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQMtc5pZu9O4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "def feature_function_binary(x,y):\n",
        "  dict1={y*(V+1)+i:x[i].item() for i in range(0,V+1)}  \n",
        "  dict2={(1-y)*(V+1)+i:0 for i in range(0,V+1)}\n",
        "  dict3={}\n",
        "  dict3.update(dict1)\n",
        "  dict3.update(dict2)\n",
        "  return dict3\n",
        "def update_theta(theta,D1,D2):\n",
        "  for feature, count in D1.items():\n",
        "    #print(\"feature=\",feature,\" count=\",count)\n",
        "    theta[feature]+=count-D2[feature]\n",
        "  return theta\n",
        "def compute_score_binary(x,y,weights):\n",
        "  total=0\n",
        "  for feature, count in feature_function_binary(x,y).items():\n",
        "    #print(\"feature=\",feature)\n",
        "    #print(\"count=\",count)\n",
        "    total+=weights[feature] * count\n",
        "  return total\n",
        "def perceptron(X,y):\n",
        "  t=0\n",
        "  theta=torch.zeros(K*(V+1),dtype=torch.float)\n",
        "  #print(\"theta=\",theta)\n",
        "  times=100\n",
        "  while(t<times):\n",
        "    i= np.random.randint(0,N,1).item()\n",
        "    x=X[i]    \n",
        "    #print(\"x=\",x)\n",
        "    hat_y=0 if compute_score_binary(x,0,theta).item()>=compute_score_binary(x,1,theta).item() else 1\n",
        "    #print(\"hat_y=\",hat_y,\"y[i]=\",y[i].item())\n",
        "    if(hat_y!=y[i].item()):\n",
        "      theta=update_theta(theta,feature_function_binary(x,y[i].item()),\n",
        "                         feature_function_binary(x,hat_y))\n",
        "    t+=1\n",
        "  return theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7qAZTH-Gji6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBDlffpuMxes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "58494928-ca3b-47e3-da30-8036e5477fc6"
      },
      "source": [
        "theta = perceptron(X,y)\n",
        "print(theta)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "feature= 6  count= 2\n",
            "feature= 7  count= 1\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 2\n",
            "feature= 10  count= 9\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 0  count= 5\n",
            "feature= 1  count= 9\n",
            "feature= 2  count= 2\n",
            "feature= 3  count= 3\n",
            "feature= 4  count= 5\n",
            "feature= 5  count= 1\n",
            "feature= 6  count= 0\n",
            "feature= 7  count= 0\n",
            "feature= 8  count= 0\n",
            "feature= 9  count= 0\n",
            "feature= 10  count= 0\n",
            "feature= 11  count= 0\n",
            "feature= 6  count= 8\n",
            "feature= 7  count= 1\n",
            "feature= 8  count= 5\n",
            "feature= 9  count= 3\n",
            "feature= 10  count= 1\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 0  count= 7\n",
            "feature= 1  count= 7\n",
            "feature= 2  count= 8\n",
            "feature= 3  count= 5\n",
            "feature= 4  count= 8\n",
            "feature= 5  count= 1\n",
            "feature= 6  count= 0\n",
            "feature= 7  count= 0\n",
            "feature= 8  count= 0\n",
            "feature= 9  count= 0\n",
            "feature= 10  count= 0\n",
            "feature= 11  count= 0\n",
            "feature= 6  count= 2\n",
            "feature= 7  count= 1\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 2\n",
            "feature= 10  count= 9\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 6  count= 8\n",
            "feature= 7  count= 1\n",
            "feature= 8  count= 5\n",
            "feature= 9  count= 3\n",
            "feature= 10  count= 1\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 0  count= 7\n",
            "feature= 1  count= 7\n",
            "feature= 2  count= 8\n",
            "feature= 3  count= 5\n",
            "feature= 4  count= 8\n",
            "feature= 5  count= 1\n",
            "feature= 6  count= 0\n",
            "feature= 7  count= 0\n",
            "feature= 8  count= 0\n",
            "feature= 9  count= 0\n",
            "feature= 10  count= 0\n",
            "feature= 11  count= 0\n",
            "feature= 6  count= 2\n",
            "feature= 7  count= 1\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 2\n",
            "feature= 10  count= 9\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 6  count= 6\n",
            "feature= 7  count= 5\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 8\n",
            "feature= 10  count= 1\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 0  count= 5\n",
            "feature= 1  count= 9\n",
            "feature= 2  count= 2\n",
            "feature= 3  count= 3\n",
            "feature= 4  count= 5\n",
            "feature= 5  count= 1\n",
            "feature= 6  count= 0\n",
            "feature= 7  count= 0\n",
            "feature= 8  count= 0\n",
            "feature= 9  count= 0\n",
            "feature= 10  count= 0\n",
            "feature= 11  count= 0\n",
            "feature= 6  count= 6\n",
            "feature= 7  count= 5\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 8\n",
            "feature= 10  count= 1\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 0  count= 5\n",
            "feature= 1  count= 7\n",
            "feature= 2  count= 3\n",
            "feature= 3  count= 9\n",
            "feature= 4  count= 7\n",
            "feature= 5  count= 1\n",
            "feature= 6  count= 0\n",
            "feature= 7  count= 0\n",
            "feature= 8  count= 0\n",
            "feature= 9  count= 0\n",
            "feature= 10  count= 0\n",
            "feature= 11  count= 0\n",
            "feature= 6  count= 2\n",
            "feature= 7  count= 1\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 2\n",
            "feature= 10  count= 9\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 6  count= 6\n",
            "feature= 7  count= 5\n",
            "feature= 8  count= 3\n",
            "feature= 9  count= 8\n",
            "feature= 10  count= 1\n",
            "feature= 11  count= 1\n",
            "feature= 0  count= 0\n",
            "feature= 1  count= 0\n",
            "feature= 2  count= 0\n",
            "feature= 3  count= 0\n",
            "feature= 4  count= 0\n",
            "feature= 5  count= 0\n",
            "feature= 0  count= 2\n",
            "feature= 1  count= 9\n",
            "feature= 2  count= 3\n",
            "feature= 3  count= 7\n",
            "feature= 4  count= 4\n",
            "feature= 5  count= 1\n",
            "feature= 6  count= 0\n",
            "feature= 7  count= 0\n",
            "feature= 8  count= 0\n",
            "feature= 9  count= 0\n",
            "feature= 10  count= 0\n",
            "feature= 11  count= 0\n",
            "tensor([-11.,  27.,  -5.,  -6.,  -4.,  -3.,  11., -27.,   5.,   6.,   4.,   3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wssGWeyjGm8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}